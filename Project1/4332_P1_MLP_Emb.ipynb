{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4332_P1_MLP_Emb.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAckpZDZG-BR"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gEmiUAEG8zx"
      },
      "source": [
        "!wget -q https://hkustconnect-my.sharepoint.com/:u:/g/personal/nnanda_connect_ust_hk/EfREjZqiZTlPqhqUPICBbPABdlgPumlaUVxPncm-_9aWIw?download=1 -O \"Project 1 - data.zip\"\n",
        "!unzip -q \"Project 1 - data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyCUH6drFgou"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_q2Kr7_Fa-g",
        "outputId": "c8f82f0f-7c0a-4b14-94fd-62e1e849bbfd"
      },
      "source": [
        "!pip -q install keras-layer-normalization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_uTe2vvFJTL"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization,\\\n",
        "    Activation, Input, Add, Concatenate, Embedding, Conv1D, MaxPool1D,\\\n",
        "    Flatten, LSTM, Bidirectional, MaxPooling1D, SimpleRNN, GRU, \\\n",
        "    SpatialDropout1D\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Z1gRo3H3Zh",
        "outputId": "2c97ca14-715d-4fd2-e7c5-cebefbae6a86"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noMKFCoiHxq1"
      },
      "source": [
        "stopwords = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Y4M188FjI3"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LdLcI3EFWIK"
      },
      "source": [
        "def load_data(split_name='train', columns=['text', 'stars']):\n",
        "    try:\n",
        "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
        "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
        "        df = df.loc[:,columns]\n",
        "        print(\"succeed!\")\n",
        "        return df\n",
        "    except:\n",
        "        print(\"Failed, then try to \")\n",
        "        print(f\"select all columns from the {split_name} split\")\n",
        "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQj5souEFnD2",
        "outputId": "7be9c717-4ad2-4f38-a7f9-3a36c8426119"
      },
      "source": [
        "train_df = load_data('train', columns=['full'])\n",
        "valid_df = load_data('valid', columns=['full'])\n",
        "test_df = load_data('test', columns=['full'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "select [full] columns from the train split\n",
            "Failed, then try to \n",
            "select all columns from the train split\n",
            "select [full] columns from the valid split\n",
            "Failed, then try to \n",
            "select all columns from the valid split\n",
            "select [full] columns from the test split\n",
            "Failed, then try to \n",
            "select all columns from the test split\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM6i0QIj2ylX"
      },
      "source": [
        "# Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbHQbGsU0sDl"
      },
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "def stem(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of stemmed words, type: list\n",
        "    e.g.\n",
        "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "\n",
        "    return [ps.stem(token).lower() for token in tokens]\n",
        "\n",
        "# Just for testing, was not used in tutorial - removing stopwords doesn't help much\n",
        "def filter_stopwords(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of filtered tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    ### equivalent code\n",
        "    # results = list()\n",
        "    # for token in tokens:\n",
        "    #     if token not in stopwords and not token.isnumeric():\n",
        "    #         results.append(token)\n",
        "    # return results\n",
        "\n",
        "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_DHdpi253v"
      },
      "source": [
        "def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n",
        "    \"\"\"\n",
        "    :param data: a list of features, type: list(list)\n",
        "    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n",
        "    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n",
        "    :param max_size: the max size of feature dict, type: int\n",
        "    return a feature dict that maps features to indices, sorted by frequencies\n",
        "    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n",
        "    \"\"\"\n",
        "    # count all features\n",
        "    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n",
        "    if max_size > 0 and min_freq == -1 and max_freq == -1:\n",
        "        valid_feats = [\"<pad>\", \"<unk>\"] + [f for f, cnt in feat_cnt.most_common(max_size-2)]\n",
        "    else:\n",
        "        valid_feats = [\"<pad>\", \"<unk>\"]\n",
        "        for f, cnt in feat_cnt.most_common():\n",
        "            if (min_freq == -1 or cnt >= min_freq) and \\\n",
        "                (max_freq == -1 or cnt <= max_freq):\n",
        "                valid_feats.append(f)\n",
        "    if max_size > 0 and len(valid_feats) > max_size:\n",
        "        valid_feats = valid_feats[:max_size]\n",
        "    print(\"Size of features:\", len(valid_feats))\n",
        "    \n",
        "    # build a mapping from features to indices\n",
        "    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n",
        "    return feats_dict\n",
        "\n",
        "def get_index_vector(feats, feats_dict, max_len):\n",
        "    \"\"\"\n",
        "    :param feats: a list of features, type: list\n",
        "    :param feats_dict: a dict from features to indices, type: dict\n",
        "    :param feats: a list of features, type: list\n",
        "    return a feature vector,\n",
        "    \"\"\"\n",
        "    # initialize the vector as all zeros\n",
        "    vector = np.zeros(max_len, dtype=np.int64)\n",
        "    for i, f in enumerate(feats):\n",
        "        if i == max_len:\n",
        "            break\n",
        "        # get the feature index, return 1 (<unk>) if the feature is not existed\n",
        "        f_idx = feats_dict.get(f, 1)\n",
        "        vector[i] = f_idx\n",
        "    return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji667tHM4oC6"
      },
      "source": [
        "# Create Input Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEMY1eAX3KEv",
        "outputId": "0ed4c0ed-c0eb-438b-efdb-75d7524e5541"
      },
      "source": [
        "min_freq = 3\n",
        "\n",
        "# load data\n",
        "train_texts, train_labels = train_df[\"text\"], train_df[\"stars\"]\n",
        "valid_texts, valid_labels = valid_df[\"text\"], valid_df[\"stars\"]\n",
        "\n",
        "# extract features\n",
        "train_tokens = [tokenize(text) for text in train_texts]\n",
        "valid_tokens = [tokenize(text) for text in valid_texts]\n",
        "\n",
        "\n",
        "train_stemmed = [stem(tokens) for tokens in train_tokens]\n",
        "valid_stemmed = [stem(tokens) for tokens in valid_tokens]\n",
        "\n",
        "# If stopwords not used\n",
        "train_feats = train_stemmed\n",
        "valid_feats = valid_stemmed\n",
        "\n",
        "# filtering stopwords didn't help much\n",
        "# train_feats = [filter_stopwords(tokens) for tokens in train_stemmed]\n",
        "# valid_feats = [filter_stopwords(tokens) for tokens in valid_stemmed]\n",
        "\n",
        "# build a mapping from features to indices\n",
        "feats_dict = get_feats_dict(chain.from_iterable(train_feats), min_freq=min_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of features: 9357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e96iHVrmK961"
      },
      "source": [
        "max_len = 100\n",
        "\n",
        "# build the feats_matrix\n",
        "# convert each example to a index vector, and then stack vectors as a matrix\n",
        "train_feats_matrix = np.vstack(\n",
        "    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n",
        "valid_feats_matrix = np.vstack(\n",
        "    [get_index_vector(f, feats_dict, max_len) for f in valid_feats])\n",
        "\n",
        "# convert labels to label_matrix\n",
        "num_classes = max(train_labels)\n",
        "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
        "train_label_matrix = keras.utils.to_categorical(train_labels-1, num_classes=num_classes)\n",
        "valid_label_matrix = keras.utils.to_categorical(valid_labels-1, num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsIHGwUv7zdM"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h85I-oTzg7U0"
      },
      "source": [
        "Add word2vec embeddings and tune hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s03zdv3dXv19",
        "outputId": "d6ece044-84bd-4b84-b7af-dd48966318e4"
      },
      "source": [
        "!wget -q https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
        "!unzip v0.9.2.zip\n",
        "%cd fastText-0.9.2\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  v0.9.2.zip\n",
            "5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe\n",
            "   creating: fastText-0.9.2/\n",
            "   creating: fastText-0.9.2/.circleci/\n",
            "  inflating: fastText-0.9.2/.circleci/cmake_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/config.yml  \n",
            "  inflating: fastText-0.9.2/.circleci/gcc_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pip_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pull_data.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/python_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/run_locally.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_circleimg.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_debian.sh  \n",
            "  inflating: fastText-0.9.2/.gitignore  \n",
            "  inflating: fastText-0.9.2/CMakeLists.txt  \n",
            "  inflating: fastText-0.9.2/CODE_OF_CONDUCT.md  \n",
            "  inflating: fastText-0.9.2/CONTRIBUTING.md  \n",
            "  inflating: fastText-0.9.2/LICENSE  \n",
            "  inflating: fastText-0.9.2/MANIFEST.in  \n",
            "  inflating: fastText-0.9.2/Makefile  \n",
            "  inflating: fastText-0.9.2/README.md  \n",
            "   creating: fastText-0.9.2/alignment/\n",
            "  inflating: fastText-0.9.2/alignment/README.md  \n",
            "  inflating: fastText-0.9.2/alignment/align.py  \n",
            "  inflating: fastText-0.9.2/alignment/eval.py  \n",
            "  inflating: fastText-0.9.2/alignment/example.sh  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_align.py  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_multialign.py  \n",
            "  inflating: fastText-0.9.2/alignment/utils.py  \n",
            "  inflating: fastText-0.9.2/classification-example.sh  \n",
            "  inflating: fastText-0.9.2/classification-results.sh  \n",
            "   creating: fastText-0.9.2/crawl/\n",
            "  inflating: fastText-0.9.2/crawl/README.md  \n",
            "  inflating: fastText-0.9.2/crawl/dedup.cc  \n",
            "  inflating: fastText-0.9.2/crawl/download_crawl.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_dedup.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_utf8.cc  \n",
            "  inflating: fastText-0.9.2/crawl/process_wet_file.sh  \n",
            "   creating: fastText-0.9.2/docs/\n",
            "  inflating: fastText-0.9.2/docs/aligned-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/api.md  \n",
            "  inflating: fastText-0.9.2/docs/autotune.md  \n",
            "  inflating: fastText-0.9.2/docs/cheatsheet.md  \n",
            "  inflating: fastText-0.9.2/docs/crawl-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/dataset.md  \n",
            "  inflating: fastText-0.9.2/docs/english-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/faqs.md  \n",
            "  inflating: fastText-0.9.2/docs/language-identification.md  \n",
            "  inflating: fastText-0.9.2/docs/options.md  \n",
            "  inflating: fastText-0.9.2/docs/pretrained-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/python-module.md  \n",
            "  inflating: fastText-0.9.2/docs/references.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-models.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-tutorial.md  \n",
            "  inflating: fastText-0.9.2/docs/support.md  \n",
            "  inflating: fastText-0.9.2/docs/unsupervised-tutorials.md  \n",
            "  inflating: fastText-0.9.2/docs/webassembly-module.md  \n",
            "  inflating: fastText-0.9.2/download_model.py  \n",
            "  inflating: fastText-0.9.2/eval.py  \n",
            "  inflating: fastText-0.9.2/fasttext.pc.in  \n",
            "  inflating: fastText-0.9.2/get-wikimedia.sh  \n",
            "   creating: fastText-0.9.2/python/\n",
            "  inflating: fastText-0.9.2/python/README.md  \n",
            "  inflating: fastText-0.9.2/python/README.rst  \n",
            "   creating: fastText-0.9.2/python/benchmarks/\n",
            "  inflating: fastText-0.9.2/python/benchmarks/README.rst  \n",
            "  inflating: fastText-0.9.2/python/benchmarks/get_word_vector.py  \n",
            "   creating: fastText-0.9.2/python/doc/\n",
            "   creating: fastText-0.9.2/python/doc/examples/\n",
            "  inflating: fastText-0.9.2/python/doc/examples/FastTextEmbeddingBag.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/bin_to_vec.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/compute_accuracy.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/get_vocab.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_supervised.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_unsupervised.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/\n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/FastText.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/__init__.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/tests/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_script.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/util/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/util.py  \n",
            "  inflating: fastText-0.9.2/quantization-example.sh  \n",
            "  inflating: fastText-0.9.2/reduce_model.py  \n",
            "  inflating: fastText-0.9.2/runtests.py  \n",
            "   creating: fastText-0.9.2/scripts/\n",
            "   creating: fastText-0.9.2/scripts/kbcompletion/\n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/README.md  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/data.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/eval.cpp  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k237.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/svo.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/wn18.sh  \n",
            "   creating: fastText-0.9.2/scripts/quantization/\n",
            "  inflating: fastText-0.9.2/scripts/quantization/quantization-results.sh  \n",
            " extracting: fastText-0.9.2/setup.cfg  \n",
            "  inflating: fastText-0.9.2/setup.py  \n",
            "   creating: fastText-0.9.2/src/\n",
            "  inflating: fastText-0.9.2/src/args.cc  \n",
            "  inflating: fastText-0.9.2/src/args.h  \n",
            "  inflating: fastText-0.9.2/src/autotune.cc  \n",
            "  inflating: fastText-0.9.2/src/autotune.h  \n",
            "  inflating: fastText-0.9.2/src/densematrix.cc  \n",
            "  inflating: fastText-0.9.2/src/densematrix.h  \n",
            "  inflating: fastText-0.9.2/src/dictionary.cc  \n",
            "  inflating: fastText-0.9.2/src/dictionary.h  \n",
            "  inflating: fastText-0.9.2/src/fasttext.cc  \n",
            "  inflating: fastText-0.9.2/src/fasttext.h  \n",
            "  inflating: fastText-0.9.2/src/loss.cc  \n",
            "  inflating: fastText-0.9.2/src/loss.h  \n",
            "  inflating: fastText-0.9.2/src/main.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.h  \n",
            "  inflating: fastText-0.9.2/src/meter.cc  \n",
            "  inflating: fastText-0.9.2/src/meter.h  \n",
            "  inflating: fastText-0.9.2/src/model.cc  \n",
            "  inflating: fastText-0.9.2/src/model.h  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.cc  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.h  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.cc  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.h  \n",
            "  inflating: fastText-0.9.2/src/real.h  \n",
            "  inflating: fastText-0.9.2/src/utils.cc  \n",
            "  inflating: fastText-0.9.2/src/utils.h  \n",
            "  inflating: fastText-0.9.2/src/vector.cc  \n",
            "  inflating: fastText-0.9.2/src/vector.h  \n",
            "   creating: fastText-0.9.2/tests/\n",
            "  inflating: fastText-0.9.2/tests/fetch_test_data.sh  \n",
            "   creating: fastText-0.9.2/webassembly/\n",
            "  inflating: fastText-0.9.2/webassembly/README.md  \n",
            "   creating: fastText-0.9.2/webassembly/doc/\n",
            "   creating: fastText-0.9.2/webassembly/doc/examples/\n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/misc.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/predict.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_supervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_unsupervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext.js  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext_wasm.cc  \n",
            "   creating: fastText-0.9.2/website/\n",
            "  inflating: fastText-0.9.2/website/README.md  \n",
            "   creating: fastText-0.9.2/website/blog/\n",
            "  inflating: fastText-0.9.2/website/blog/2016-08-18-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-05-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-10-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2019-06-25-blog-post.md  \n",
            "   creating: fastText-0.9.2/website/core/\n",
            "  inflating: fastText-0.9.2/website/core/Footer.js  \n",
            "  inflating: fastText-0.9.2/website/package.json  \n",
            "   creating: fastText-0.9.2/website/pages/\n",
            "   creating: fastText-0.9.2/website/pages/en/\n",
            "  inflating: fastText-0.9.2/website/pages/en/index.js  \n",
            "  inflating: fastText-0.9.2/website/sidebars.json  \n",
            "  inflating: fastText-0.9.2/website/siteConfig.js  \n",
            "   creating: fastText-0.9.2/website/static/\n",
            "   creating: fastText-0.9.2/website/static/docs/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h_source.html  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/bc_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/bdwn.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classes.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/closed.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doc.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/doxygen.css  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doxygen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dynsections.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/favicon.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderclosed.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderopen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_0x7e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_g.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_i.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_k.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_l.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_m.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_n.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_o.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_p.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_q.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_r.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_s.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_t.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_u.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_v.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_vars.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_w.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_z.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_defs.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/index.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/jquery.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menu.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menudata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_enum.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_type.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/nav_f.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_g.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_h.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreedata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/open.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/resize.js  \n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/search/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/close.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/mag_sel.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/nomatches.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_l.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search_m.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_r.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/searchdata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/splitbar.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_off.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_on.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_a.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_b.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_h.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/tabs.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/fasttext.css  \n",
            "   creating: fastText-0.9.2/website/static/img/\n",
            "   creating: fastText-0.9.2/website/static/img/authors/\n",
            "  inflating: fastText-0.9.2/website/static/img/authors/armand_joulin.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/christian_puhrsch.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/edouard_grave.jpeg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/piotr_bojanowski.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/tomas_mikolov.jpg  \n",
            "   creating: fastText-0.9.2/website/static/img/blog/\n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/cbo_vs_skipgram.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-api.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-bg-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-square.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-faq.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-tutorial.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/logo-color.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-black.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-blue.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-red.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/ogimage.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/oss_logo.png  \n",
            "  inflating: fastText-0.9.2/website/static/tabber.js  \n",
            "  inflating: fastText-0.9.2/wikifil.pl  \n",
            "  inflating: fastText-0.9.2/word-vector-example.sh  \n",
            "/content/fastText-0.9.2\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63o9K6_jaKzx",
        "outputId": "3dac57e4-67f3-4f9c-e2d5-1cbf4062da5b"
      },
      "source": [
        "!cp fasttext ../\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVMk2JdYbuhL"
      },
      "source": [
        "with open('reviews.txt', 'w') as filehandle:\n",
        "    for sent in train_feats:\n",
        "        combined_sent = (\" \").join(sent)\n",
        "        filehandle.write('%s\\n' % combined_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNpzTr0_4iS"
      },
      "source": [
        "os.makedirs(\"models\", exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCodwuVXdrZI",
        "outputId": "a4b1a582-8c93-4257-ee43-7b9e72265ed3"
      },
      "source": [
        "!./fasttext skipgram -input ./reviews.txt -output models/word2vec -dim 100 -minCount 3 -epoch 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rRead 1M words\rRead 1M words\n",
            "Number of words:  9356\n",
            "Number of labels: 0\n",
            "Progress: 100.0% words/sec/thread:   21276 lr:  0.000000 avg.loss:  2.333479 ETA:   0h 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fBVhVYj_nhw",
        "outputId": "48f6778d-d4aa-4011-8296-436031721f7e"
      },
      "source": [
        "embedding_matrix = np.zeros((len(feats_dict), 100), dtype=np.float32)\n",
        "with open(\"models/word2vec.vec\", \"r\") as f:\n",
        "    n_words, n_dim = f.readline().split()\n",
        "    n_words, n_dim = int(n_words), int(n_dim) \n",
        "    print(\"number of words:\", n_words, \"word dimension:\", n_dim)\n",
        "    while True:\n",
        "        line = f.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        word, vec = line.split(\" \", 1)\n",
        "        word_idx = feats_dict.get(word, -1)\n",
        "        if word_idx != -1:\n",
        "            embedding_matrix[word_idx] = np.array(vec.split(), dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words: 9356 word dimension: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOMKQXa0AbFX",
        "outputId": "e5408ae3-365f-46a8-ce22-98debbe160fc"
      },
      "source": [
        "print(embedding_matrix[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [ 2.4303e-01  7.5073e-02 -4.5550e-02  8.0304e-03 -5.5353e-05  1.6198e-01\n",
            "  -1.6404e-02 -1.5929e-01  3.3570e-01  2.2053e-01  1.8282e-01  2.6733e-02\n",
            "   9.7164e-02  5.2990e-03  1.7343e-02  5.3896e-02  6.5932e-02 -1.4756e-01\n",
            "  -1.4054e-01  7.5921e-02  2.8097e-01  9.4828e-02 -3.3448e-02  1.0784e-01\n",
            "   4.4510e-03 -1.4672e-01  6.4696e-02  4.2789e-02 -1.3760e-01  2.0544e-01\n",
            "   5.9319e-02  5.6432e-02  4.8918e-02  7.9963e-02  8.5927e-02  1.6364e-01\n",
            "   2.1742e-01 -1.6132e-01 -1.6932e-03 -7.9033e-02  1.7325e-01  1.5154e-01\n",
            "   9.0923e-02  6.5090e-02 -5.8917e-02 -2.6573e-01  1.4952e-01  1.3375e-01\n",
            "   5.7224e-02 -1.0160e-01 -1.6457e-01  1.0883e-01 -2.5096e-01 -1.1557e-02\n",
            "  -3.8778e-01 -7.3166e-02 -3.2753e-02  1.3202e-01 -1.4406e-02  2.0219e-01\n",
            "   6.7793e-02 -1.3104e-01 -8.9853e-03 -1.0858e-01 -4.4151e-02  1.2445e-01\n",
            "   1.5197e-01  4.4685e-01 -3.6024e-02 -2.3376e-02  1.1234e-01 -2.0574e-02\n",
            "   1.2560e-01 -7.0494e-02  6.5301e-02  1.4872e-01  7.7458e-02 -1.6981e-01\n",
            "   1.6133e-02 -1.1312e-01  2.0675e-01 -1.2423e-01  4.1290e-02  1.1984e-01\n",
            "   7.7184e-02 -1.9751e-01 -7.7911e-02 -2.0149e-01 -1.6155e-02 -1.0159e-01\n",
            "   6.5575e-02  3.0301e-03  2.1106e-01 -3.2183e-02 -1.4207e-01 -6.1364e-02\n",
            "  -1.1160e-01  2.7037e-01  1.6104e-01  1.1340e-02]\n",
            " [ 2.9344e-01  1.6492e-01  2.6985e-02  3.6942e-03  1.0439e-01  1.8118e-01\n",
            "   7.6542e-02 -2.1965e-01  2.5408e-01  2.3053e-01  8.2219e-02  1.6160e-01\n",
            "   1.1602e-01  2.9328e-02  8.6496e-02 -2.1093e-02  7.1389e-02 -1.1143e-01\n",
            "  -2.3176e-01  1.3681e-01  2.3131e-01 -7.1726e-02  1.4979e-01  8.0277e-02\n",
            "  -1.4486e-01 -1.2811e-01  1.8333e-01  1.1809e-01 -1.8799e-01  1.6096e-01\n",
            "   1.3396e-02  1.1356e-01 -2.6599e-02  6.8508e-02  9.8047e-02  1.8614e-01\n",
            "   2.0066e-01 -1.2735e-01 -1.1837e-02 -2.0622e-02  3.3680e-02  1.2987e-01\n",
            "   7.2993e-02 -6.7277e-02 -2.7344e-02 -2.5285e-01  3.5233e-01  1.9774e-01\n",
            "   7.0891e-02  9.8209e-03 -9.7869e-02  1.0162e-01 -1.8025e-01  1.2180e-01\n",
            "  -4.8807e-01 -6.2514e-02  2.5714e-02  4.9733e-02 -1.2789e-01  8.7158e-02\n",
            "  -3.8783e-02  5.6742e-02 -7.7625e-02  3.6487e-02 -1.0573e-01  2.8250e-01\n",
            "   5.2848e-02  3.9068e-01 -9.8446e-02 -8.8099e-02  2.4108e-01 -1.7838e-02\n",
            "   6.1360e-02 -5.5147e-02 -8.3354e-02  1.8432e-01  7.7514e-02 -1.3816e-01\n",
            "   8.9443e-02 -4.3319e-02  1.1787e-01 -1.5192e-01  9.7334e-02  5.6038e-02\n",
            "   5.3742e-02 -2.7970e-01 -2.4051e-01 -1.2534e-01 -7.8680e-03 -7.7205e-02\n",
            "   4.3877e-02  7.4669e-02  2.3443e-01  1.4607e-02 -1.4460e-01 -1.4444e-01\n",
            "  -2.0073e-01  2.7059e-01  2.0239e-01 -1.1217e-01]\n",
            " [ 2.0595e-01  5.1997e-02  1.6330e-02 -4.6522e-02  6.2099e-02  8.8544e-02\n",
            "  -6.6576e-02 -1.8373e-01  3.6051e-01  8.0530e-02  1.5064e-01  3.3682e-02\n",
            "   9.5596e-02  2.6873e-02  1.0205e-01 -1.5770e-01  7.3818e-02 -2.6717e-02\n",
            "  -2.2458e-01  2.0791e-01  2.9713e-01 -1.5896e-02  3.5728e-02  5.7741e-02\n",
            "   3.0605e-02 -1.1787e-01  1.2287e-02 -4.3299e-02 -1.4563e-01  1.4077e-01\n",
            "  -9.5360e-02  1.4564e-02  4.6287e-02  9.6882e-02  2.6071e-01  8.9678e-02\n",
            "   2.9493e-01 -7.6895e-02 -3.0025e-02 -2.3838e-02  1.3451e-01  1.2312e-01\n",
            "   8.5154e-02  5.2321e-02 -6.8405e-02 -2.6173e-01  2.8646e-01  1.2130e-01\n",
            "   3.0151e-02 -1.1007e-01 -1.5513e-01  2.1079e-01 -1.4681e-01 -3.7267e-02\n",
            "  -3.5570e-01 -6.3111e-02 -1.3408e-01  4.6576e-02 -1.5871e-02  1.4419e-01\n",
            "   2.7047e-02  1.5048e-02 -2.2546e-01 -2.1168e-01 -3.2726e-03  2.4169e-01\n",
            "   2.0895e-02  3.0547e-01  4.0354e-02 -2.9867e-02  2.2197e-01 -1.0947e-01\n",
            "   7.9010e-02  1.2592e-02  9.8723e-02  1.2502e-01  5.4320e-02 -7.6543e-02\n",
            "   1.3148e-02  1.0069e-02  2.5028e-01 -5.9735e-02  2.8316e-02  7.8709e-02\n",
            "   2.1402e-03 -2.5194e-01 -5.5289e-02 -1.5787e-01  1.1820e-02 -5.5874e-02\n",
            "   1.1629e-02  4.5408e-02  1.5090e-01 -6.1903e-02 -9.4669e-02 -1.5920e-01\n",
            "  -8.3095e-02  1.3335e-01  6.7700e-02  5.9263e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSpjs52e3Gj6"
      },
      "source": [
        "# RNN Builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzH7JhQf3DJN"
      },
      "source": [
        "def build_MLP_Emb(input_length, vocab_size, embedding_size,\n",
        "              hidden_size, output_size,\n",
        "              num_rnn_layers, num_mlp_layers,\n",
        "              rnn_type=\"lstm\",\n",
        "              bidirectional=False,\n",
        "              embedding_matrix=None,\n",
        "              activation=\"tanh\",\n",
        "              dropout_rate=0.0,\n",
        "              batch_norm=False,\n",
        "              l2_reg=0.0,\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"Adam\",\n",
        "              learning_rate=0.001,\n",
        "              metric=\"accuracy\",\n",
        "              num_filters=128,\n",
        "              kernel_size=2,\n",
        "              strides=1):\n",
        "    \"\"\"\n",
        "    :param input_length: the maximum length of sentences, type: int\n",
        "    :param vocab_size: the vacabulary size, type: int\n",
        "    :param embedding_size: the dimension of word representations, type: int\n",
        "    :param hidden_size: the dimension of the hidden states, type: int\n",
        "    :param output_size: the dimension of the prediction, type: int\n",
        "    :param num_rnn_layers: the number of layers of the RNN, type: int\n",
        "    :param num_mlp_layers: the number of layers of the MLP, type: int\n",
        "    :param rnn_type: the type of RNN, type: str\n",
        "    :param bidirectional: whether to use bidirectional rnn, type: bool\n",
        "    :param activation: the activation type, type: str\n",
        "    :param dropout_rate: the probability of dropout, type: float\n",
        "    :param batch_norm: whether to enable batch normalization, type: bool\n",
        "    :param l2_reg: the weight for the L2 regularizer, type: str\n",
        "    :param loss: the training loss, type: str\n",
        "    :param optimizer: the optimizer, type: str\n",
        "    :param learning_rate: the learning rate for the optimizer, type: float\n",
        "    :param metric: the metric, type: str\n",
        "    return a RNN for text classification,\n",
        "    # activation document: https://keras.io/activations/\n",
        "    # dropout document: https://keras.io/layers/core/#dropout\n",
        "    # embedding document: https://keras.io/layers/embeddings/#embedding\n",
        "    # recurrent layers document: https://keras.io/layers/recurrent\n",
        "    # batch normalization document: https://keras.io/layers/normalization/\n",
        "    # losses document: https://keras.io/losses/\n",
        "    # optimizers document: https://keras.io/optimizers/\n",
        "    # metrics document: https://keras.io/metrics/\n",
        "    \"\"\"\n",
        "    x = Input(shape=(input_length,))\n",
        "    \n",
        "    ################################\n",
        "    ###### Word Representation #####\n",
        "    ################################\n",
        "    # word representation layer\n",
        "    if embedding_matrix is not None:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_size,\n",
        "                        input_length=input_length,\n",
        "                        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                        trainable=True)(x)\n",
        "    else:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_size,\n",
        "                        input_length=input_length,\n",
        "                        embeddings_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=0))(x)\n",
        "    \n",
        "    ################################\n",
        "    ####### Recurrent Layers #######\n",
        "    ################################\n",
        "    # recurrent layers\n",
        "    if rnn_type == \"rnn\":\n",
        "        fn = SimpleRNN\n",
        "    elif rnn_type == \"lstm\":\n",
        "        fn = LSTM\n",
        "    elif rnn_type == \"gru\":\n",
        "        fn = GRU\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    h = emb\n",
        "\n",
        "    # for i in range(num_rnn_layers):\n",
        "    #     is_last = (i == num_rnn_layers-1)\n",
        "    #     if bidirectional:\n",
        "    #         h = Bidirectional(fn(hidden_size,\n",
        "    #                              kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n",
        "    #                              recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n",
        "    #                              return_sequences=not is_last))(h)\n",
        "    #     else:\n",
        "    #         h = fn(hidden_size,\n",
        "    #                kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n",
        "    #                recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n",
        "    #                return_sequences=not is_last)(h)\n",
        "    #     h = Dropout(dropout_rate, seed=0)(h)\n",
        "\n",
        "    conv = Conv1D(filters=num_filters, kernel_size=kernel_size, padding=\"valid\", strides=strides)(h)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "        \n",
        "    maxpool = MaxPool1D(pool_size=(input_length-kernel_size)//strides+1)(conv)\n",
        "    # maxpool = MaxPool1D()(conv)\n",
        "\n",
        "    maxpool = Flatten()(maxpool)\n",
        "\n",
        "    h = Dropout(dropout_rate)(maxpool)\n",
        "    \n",
        "    ################################\n",
        "    #### Fully Connected Layers ####\n",
        "    ################################\n",
        "    # multi-layer perceptron\n",
        "    for i in range(num_mlp_layers-1):\n",
        "        new_h = Dense(hidden_size,\n",
        "                      kernel_initializer=keras.initializers.he_normal(seed=0),\n",
        "                      bias_initializer=\"zeros\",\n",
        "                      kernel_regularizer=keras.regularizers.l2(l2_reg))(h)\n",
        "        # add batch normalization layer\n",
        "        if batch_norm:\n",
        "            new_h = BatchNormalization()(new_h)\n",
        "        # add residual connection\n",
        "        if i == 0:\n",
        "            h = new_h\n",
        "        else:\n",
        "            h = Add()([h, new_h])\n",
        "        # add activation\n",
        "        h = Activation(activation)(h)\n",
        "    y = Dense(output_size,\n",
        "              activation=\"softmax\",\n",
        "              kernel_initializer=keras.initializers.he_normal(seed=0),\n",
        "              bias_initializer=\"zeros\")(h)\n",
        "    \n",
        "    # set the loss, the optimizer, and the metric\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    elif optimizer == \"RMSprop\":\n",
        "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer == \"Adam\":\n",
        "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    model = Model(x, y)\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi8axw1anGRm",
        "outputId": "14737157-d289-457c-d3f7-8b5c0ad81cd6"
      },
      "source": [
        "model = build_MLP_Emb(input_length=max_len, vocab_size=len(feats_dict),\n",
        "                  embedding_size=100, hidden_size=100, output_size=num_classes,\n",
        "                  rnn_type=\"lstm\", num_rnn_layers=0, bidirectional=True, num_mlp_layers=2,\n",
        "                  embedding_matrix=embedding_matrix,\n",
        "                  activation=\"tanh\",\n",
        "                  batch_norm=True,\n",
        "                  l2_reg=0.005, dropout_rate=0.5)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 100)          935700    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 99, 128)           25728     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 99, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               12900     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 975,233\n",
            "Trainable params: 975,033\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXzIZy_JZD6x"
      },
      "source": [
        "def Emb_Lstm_Cnn_Mlp_modified(input_length=max_len, vocab_size=len(feats_dict), \n",
        "                     embedding_size=100, hidden_size=100, \n",
        "                     num_filters=100, kernel_size=2, strides=1, \n",
        "                     output_size=num_classes, learning_rate=0.001,\n",
        "                     dropout_rate=0.5, recurrent_dropout_rate=0.5, \n",
        "                     train=False, optimizer=\"RMSprop\"):\n",
        "    x = Input(shape=(input_length,))\n",
        "    if embedding_matrix is not None:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=embedding_size,\n",
        "                            input_length=input_length,\n",
        "                            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                            trainable=train)(x)\n",
        "    else:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_size,\n",
        "                        input_length=input_length,\n",
        "                        embeddings_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=0))(x)\n",
        "\n",
        "    emb = SpatialDropout1D(dropout_rate)(emb)\n",
        "\n",
        "    rec = Bidirectional(LSTM(hidden_size,\n",
        "                        kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n",
        "                        recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n",
        "                        return_sequences=True, dropout=dropout_rate, recurrent_activation=\"sigmoid\"))(emb)\n",
        "\n",
        "    h = Concatenate()([emb, rec])\n",
        "\n",
        "    # h = Dropout(dropout_rate)(h)\n",
        "\n",
        "    conv = Conv1D(filters=num_filters, kernel_size=kernel_size, padding=\"valid\", strides=strides)(h)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "        \n",
        "    maxpool = MaxPool1D(pool_size=(input_length-kernel_size)//strides+1)(conv)\n",
        "    # maxpool = MaxPool1D()(conv)\n",
        "\n",
        "    maxpool = Flatten()(maxpool)\n",
        "\n",
        "    maxpool = Dropout(dropout_rate)(maxpool) # testing\n",
        "\n",
        "    y = Dense(output_size,\n",
        "              activation=\"softmax\",\n",
        "              kernel_initializer=keras.initializers.he_normal(seed=0),\n",
        "              bias_initializer=\"zeros\")(maxpool)\n",
        "\n",
        "    model = Model(x, y)\n",
        "    # optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    # optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    # print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-yn5sSbZHqa",
        "outputId": "bdb3e858-fec1-442c-a71c-4a24d70cf17e"
      },
      "source": [
        "model = Emb_Lstm_Cnn_Mlp_modified()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 100)     935700      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 100, 100)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 100, 200)     160800      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 100, 300)     0           spatial_dropout1d[0][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 99, 100)      60100       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 99, 100)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 100)          0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            505         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,157,105\n",
            "Trainable params: 221,405\n",
            "Non-trainable params: 935,700\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1pVX8wMZV7v",
        "outputId": "a6f4b598-2c55-48db-cf13-25aadc0c05d9"
      },
      "source": [
        "os.makedirs(\"models\", exist_ok=True)\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(\"models\", \"weights_word2vec_cnn_mlp.hdf5\"),\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True)\n",
        "earlystopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "model = Emb_Lstm_Cnn_Mlp_modified()\n",
        "word2vec_cnn_mlp_modified_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                                    validation_split=0.1,\n",
        "                                    epochs=100, batch_size=100, verbose=1,\n",
        "                                    callbacks=[checkpointer, earlystopping, reduce_lr])\n",
        "model = keras.models.load_model(os.path.join(\"models\", \"weights_word2vec_cnn_mlp.hdf5\"))\n",
        "\n",
        "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
        "                             batch_size=100)\n",
        "valid_score = model.evaluate(valid_feats_matrix, valid_label_matrix,\n",
        "                            batch_size=100)\n",
        "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
        "print(\"valid loss:\", valid_score[0], \"valid accuracy\", valid_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "90/90 [==============================] - 39s 390ms/step - loss: 1.6706 - accuracy: 0.2796 - val_loss: 1.4983 - val_accuracy: 0.3390\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.33900, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 34s 382ms/step - loss: 1.4393 - accuracy: 0.3923 - val_loss: 1.3628 - val_accuracy: 0.4460\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.33900 to 0.44600, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 34s 383ms/step - loss: 1.3729 - accuracy: 0.4166 - val_loss: 1.2929 - val_accuracy: 0.4570\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.44600 to 0.45700, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 34s 382ms/step - loss: 1.3154 - accuracy: 0.4503 - val_loss: 1.2278 - val_accuracy: 0.5080\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.45700 to 0.50800, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 34s 383ms/step - loss: 1.2940 - accuracy: 0.4665 - val_loss: 1.2279 - val_accuracy: 0.4920\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.50800\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 34s 383ms/step - loss: 1.2645 - accuracy: 0.4739 - val_loss: 1.1712 - val_accuracy: 0.5260\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.50800 to 0.52600, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 34s 382ms/step - loss: 1.2184 - accuracy: 0.4875 - val_loss: 1.1990 - val_accuracy: 0.5180\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.52600\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 34s 383ms/step - loss: 1.2173 - accuracy: 0.4883 - val_loss: 1.1693 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.52600\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 34s 382ms/step - loss: 1.2194 - accuracy: 0.4812 - val_loss: 1.1519 - val_accuracy: 0.5220\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.52600\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 35s 386ms/step - loss: 1.2043 - accuracy: 0.4912 - val_loss: 1.1890 - val_accuracy: 0.5080\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.52600\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1910 - accuracy: 0.5012 - val_loss: 1.1674 - val_accuracy: 0.5130\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.52600\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1889 - accuracy: 0.5093 - val_loss: 1.1408 - val_accuracy: 0.5240\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.52600\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1626 - accuracy: 0.5128 - val_loss: 1.1470 - val_accuracy: 0.5300\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.52600 to 0.53000, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 34s 375ms/step - loss: 1.1629 - accuracy: 0.5131 - val_loss: 1.1115 - val_accuracy: 0.5360\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.53000 to 0.53600, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1417 - accuracy: 0.5204 - val_loss: 1.1070 - val_accuracy: 0.5290\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.53600\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 34s 375ms/step - loss: 1.1595 - accuracy: 0.5180 - val_loss: 1.1147 - val_accuracy: 0.5300\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53600\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1559 - accuracy: 0.5009 - val_loss: 1.1308 - val_accuracy: 0.5360\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.53600\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1411 - accuracy: 0.5192 - val_loss: 1.1350 - val_accuracy: 0.5260\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53600\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1468 - accuracy: 0.5167 - val_loss: 1.1093 - val_accuracy: 0.5380\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.53600 to 0.53800, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1365 - accuracy: 0.5176 - val_loss: 1.1046 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53800 to 0.54100, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 34s 377ms/step - loss: 1.1206 - accuracy: 0.5313 - val_loss: 1.1098 - val_accuracy: 0.5390\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.54100\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1254 - accuracy: 0.5256 - val_loss: 1.1090 - val_accuracy: 0.5400\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.54100\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 34s 381ms/step - loss: 1.1329 - accuracy: 0.5266 - val_loss: 1.1094 - val_accuracy: 0.5380\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.54100\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 34s 380ms/step - loss: 1.1194 - accuracy: 0.5355 - val_loss: 1.1065 - val_accuracy: 0.5400\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.54100\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 34s 380ms/step - loss: 1.1166 - accuracy: 0.5360 - val_loss: 1.1045 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.54100\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1185 - accuracy: 0.5347 - val_loss: 1.1040 - val_accuracy: 0.5380\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.54100\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1133 - accuracy: 0.5416 - val_loss: 1.1031 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.54100\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1223 - accuracy: 0.5295 - val_loss: 1.1039 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.54100\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 34s 378ms/step - loss: 1.1117 - accuracy: 0.5391 - val_loss: 1.1031 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.54100\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 34s 376ms/step - loss: 1.1065 - accuracy: 0.5341 - val_loss: 1.1035 - val_accuracy: 0.5380\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.54100\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 34s 376ms/step - loss: 1.1262 - accuracy: 0.5333 - val_loss: 1.1036 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.54100\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 34s 376ms/step - loss: 1.1261 - accuracy: 0.5322 - val_loss: 1.1035 - val_accuracy: 0.5370\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.54100\n",
            "Epoch 00032: early stopping\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 1.0248 - accuracy: 0.5851\n",
            "20/20 [==============================] - 3s 125ms/step - loss: 1.0450 - accuracy: 0.5730\n",
            "training loss: 1.0247631072998047 training accuracy 0.585099995136261\n",
            "valid loss: 1.044968605041504 valid accuracy 0.5730000138282776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsChUTCZkrTs",
        "outputId": "eb9b4d19-0436-4e62-c9e0-6e249d1eeb6c"
      },
      "source": [
        "# model = build_MLP_Emb(input_length=max_len, vocab_size=len(feats_dict),\n",
        "#                   embedding_size=100, hidden_size=100, output_size=num_classes,\n",
        "#                   rnn_type=\"lstm\", num_rnn_layers=0, bidirectional=True, num_mlp_layers=2,\n",
        "#                   embedding_matrix=embedding_matrix,\n",
        "#                   activation=\"tanh\",\n",
        "#                   batch_norm=True,\n",
        "#                   l2_reg=0.005, dropout_rate=0.5)\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(\"models\", \"weights_word2vec_cnn_mlp.hdf5\"),\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True)\n",
        "earlystopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=15,\n",
        "    verbose=1)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=7, verbose=1)\n",
        "\n",
        "model = build_MLP_Emb(input_length=max_len, vocab_size=len(feats_dict),\n",
        "                  embedding_size=100, hidden_size=100, output_size=num_classes,\n",
        "                  rnn_type=\"lstm\", num_rnn_layers=0, bidirectional=True, num_mlp_layers=2,\n",
        "                  embedding_matrix=embedding_matrix,\n",
        "                  activation=\"relu\",\n",
        "                  batch_norm=True,\n",
        "                  l2_reg=0.005, dropout_rate=0.5)\n",
        "word2vec_cnn_mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                                    validation_split=0.1,\n",
        "                                    epochs=100, batch_size=100, verbose=1,\n",
        "                                    callbacks=[checkpointer, earlystopping, reduce_lr])\n",
        "model = keras.models.load_model(os.path.join(\"models\", \"weights_word2vec_cnn_mlp.hdf5\"))\n",
        "\n",
        "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
        "                             batch_size=100)\n",
        "valid_score = model.evaluate(valid_feats_matrix, valid_label_matrix,\n",
        "                            batch_size=100)\n",
        "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
        "print(\"valid loss:\", valid_score[0], \"valid accuracy\", valid_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "90/90 [==============================] - 7s 67ms/step - loss: 2.7007 - accuracy: 0.2596 - val_loss: 2.2209 - val_accuracy: 0.3790\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37900, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 6s 70ms/step - loss: 2.1314 - accuracy: 0.3880 - val_loss: 1.8221 - val_accuracy: 0.4770\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.37900 to 0.47700, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 6s 72ms/step - loss: 1.7172 - accuracy: 0.4862 - val_loss: 1.6154 - val_accuracy: 0.4970\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.47700 to 0.49700, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 6s 63ms/step - loss: 1.4553 - accuracy: 0.5440 - val_loss: 1.4702 - val_accuracy: 0.5220\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.49700 to 0.52200, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 6s 71ms/step - loss: 1.2968 - accuracy: 0.5785 - val_loss: 1.3595 - val_accuracy: 0.5280\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.52200 to 0.52800, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 6s 66ms/step - loss: 1.1396 - accuracy: 0.6207 - val_loss: 1.2963 - val_accuracy: 0.5190\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.52800\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 6s 71ms/step - loss: 1.0335 - accuracy: 0.6497 - val_loss: 1.2735 - val_accuracy: 0.5110\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.52800\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 6s 67ms/step - loss: 0.9524 - accuracy: 0.6756 - val_loss: 1.2331 - val_accuracy: 0.5350\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.52800 to 0.53500, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 6s 64ms/step - loss: 0.8626 - accuracy: 0.6978 - val_loss: 1.2245 - val_accuracy: 0.5250\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.53500\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 6s 69ms/step - loss: 0.7828 - accuracy: 0.7300 - val_loss: 1.2454 - val_accuracy: 0.5310\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.53500\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 6s 63ms/step - loss: 0.7397 - accuracy: 0.7498 - val_loss: 1.2727 - val_accuracy: 0.5260\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.53500\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 6s 72ms/step - loss: 0.6657 - accuracy: 0.7735 - val_loss: 1.2992 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.53500 to 0.54100, saving model to models/weights_word2vec_cnn_mlp.hdf5\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 6s 71ms/step - loss: 0.6257 - accuracy: 0.7937 - val_loss: 1.3119 - val_accuracy: 0.5220\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.54100\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 6s 71ms/step - loss: 0.5784 - accuracy: 0.8045 - val_loss: 1.3481 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.54100\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 6s 68ms/step - loss: 0.5641 - accuracy: 0.8068 - val_loss: 1.3859 - val_accuracy: 0.5090\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.54100\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 6s 68ms/step - loss: 0.5228 - accuracy: 0.8184 - val_loss: 1.4085 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.54100\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 6s 70ms/step - loss: 0.5106 - accuracy: 0.8243 - val_loss: 1.4378 - val_accuracy: 0.5110\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.54100\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 6s 69ms/step - loss: 0.4752 - accuracy: 0.8397 - val_loss: 1.5044 - val_accuracy: 0.5170\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.54100\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 7s 74ms/step - loss: 0.4417 - accuracy: 0.8551 - val_loss: 1.5003 - val_accuracy: 0.5080\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.54100\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 6s 66ms/step - loss: 0.4404 - accuracy: 0.8498 - val_loss: 1.5066 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.54100\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 6s 68ms/step - loss: 0.3937 - accuracy: 0.8686 - val_loss: 1.5006 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.54100\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 6s 70ms/step - loss: 0.3623 - accuracy: 0.8864 - val_loss: 1.5089 - val_accuracy: 0.5110\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.54100\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 6s 72ms/step - loss: 0.3506 - accuracy: 0.8869 - val_loss: 1.5076 - val_accuracy: 0.5170\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.54100\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 6s 72ms/step - loss: 0.3341 - accuracy: 0.8942 - val_loss: 1.5198 - val_accuracy: 0.5120\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.54100\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 6s 72ms/step - loss: 0.3361 - accuracy: 0.8888 - val_loss: 1.5166 - val_accuracy: 0.5130\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.54100\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 7s 72ms/step - loss: 0.3478 - accuracy: 0.8880 - val_loss: 1.5186 - val_accuracy: 0.5170\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.54100\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 7s 74ms/step - loss: 0.3275 - accuracy: 0.8968 - val_loss: 1.5238 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.54100\n",
            "Epoch 00027: early stopping\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.5164 - accuracy: 0.8661\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.2578 - accuracy: 0.5330\n",
            "training loss: 0.5163646936416626 training accuracy 0.866100013256073\n",
            "valid loss: 1.2578389644622803 valid accuracy 0.5329999923706055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI_maSXRlijr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}