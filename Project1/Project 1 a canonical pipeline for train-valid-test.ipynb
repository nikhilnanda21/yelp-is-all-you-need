{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is an example to show how three parts of the data should be used. Feel free to change the models to get better scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'stars']):\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"succeed!\")\n",
    "        return df\n",
    "    except:\n",
    "        print(\"Failed, then try to \")\n",
    "        print(f\"select all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, stars] columns from the train split\n",
      "succeed!\n",
      "select [text, stars] columns from the valid split\n",
      "succeed!\n",
      "select [text, stars] columns from the test split\n",
      "Failed, then try to \n",
      "select all columns from the test split\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train')\n",
    "valid_df = load_data('valid')\n",
    "test_df = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7YYrZ9LgjpKLTtF-huhJug</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-04 21:21:45</td>\n",
       "      <td>0</td>\n",
       "      <td>b8-ELBwhmDKcmcM8icT86g</td>\n",
       "      <td>I took the UP Train to Union Station to catch ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9Lglv-v8SRo_S-IyvFBmbw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gyNixTgp1yFX97soBZpZ7Q</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-10 00:04:01</td>\n",
       "      <td>0</td>\n",
       "      <td>rBpAJhIen_V-zLoXZIcROg</td>\n",
       "      <td>We worked with Fitness with a Twist for part o...</td>\n",
       "      <td>1</td>\n",
       "      <td>zIl62G84XT2BwSIAjjjvYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vNWfQrQCa_XijstJbylcDQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-28 01:23:21</td>\n",
       "      <td>2</td>\n",
       "      <td>_pALaDG6se9OTkGGhyhnNA</td>\n",
       "      <td>It's your typical, average, run-of-the-mill co...</td>\n",
       "      <td>1</td>\n",
       "      <td>WP7FsUsgNW24s7HH5xi7pg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wfxmuA7LbKZKVLV58EiWBw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-19 03:48:40</td>\n",
       "      <td>0</td>\n",
       "      <td>ru8fpA1Uk0tTFtO5hLM49g</td>\n",
       "      <td>We went to Outback today to celebrate my daugh...</td>\n",
       "      <td>0</td>\n",
       "      <td>yLSj54f2YgGQu-lhPIhMTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5jTmjxb1X34EfcY1gos4tw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-04 23:29:46</td>\n",
       "      <td>0</td>\n",
       "      <td>fRPgwuFoY6SriToXZyaOQA</td>\n",
       "      <td>We Went to see Nashville unplugged a country c...</td>\n",
       "      <td>1</td>\n",
       "      <td>73-u0a3G9Le4GWG7zLYWtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>rKl9yHz4LmQzD70yXBaRlg</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-24 02:43:01</td>\n",
       "      <td>0</td>\n",
       "      <td>oZxqo6rspUimmoqKl0_qdA</td>\n",
       "      <td>This was an ok Burger joint. This chain is big...</td>\n",
       "      <td>1</td>\n",
       "      <td>XxG5SZOPkihWeJe3r9XL8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Hqs4YNST_ZHbshwyi4bnsQ</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-12-30 08:01:06</td>\n",
       "      <td>1</td>\n",
       "      <td>C_oCpNq91uTtOYUs2cChdg</td>\n",
       "      <td>Came here on a whim as we were passing through...</td>\n",
       "      <td>3</td>\n",
       "      <td>acPFDB6xB5qtcwTCI2wLvg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>46hnat0aLao-qYWZkN9aBg</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-28 15:40:22</td>\n",
       "      <td>1</td>\n",
       "      <td>qMrxDB5fm8wIzexUp643xQ</td>\n",
       "      <td>This is my favorite Mexican food place on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>TJoILHOxI_K5kJUye0BtbA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>BGGQOJQTQerEQu0kHbT_UQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-02 22:24:13</td>\n",
       "      <td>0</td>\n",
       "      <td>HrejfPp6Xduy5Pv7i-is1A</td>\n",
       "      <td>Stopped in here on 3/24/16 around 8pm when the...</td>\n",
       "      <td>0</td>\n",
       "      <td>PTHCHcBhJbyNS3hMSQ2pYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>I_a74zmgR-X03LsKISWPcg</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-08 00:16:47</td>\n",
       "      <td>0</td>\n",
       "      <td>cXo09g5VbXvLHtg52wqhdg</td>\n",
       "      <td>Who knew that you could get really good Asian ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q8BS0HbtMqH295h46UsL7w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  cool                 date  funny  \\\n",
       "0     7YYrZ9LgjpKLTtF-huhJug     0  2018-04-04 21:21:45      0   \n",
       "1     gyNixTgp1yFX97soBZpZ7Q     1  2013-07-10 00:04:01      0   \n",
       "2     vNWfQrQCa_XijstJbylcDQ     1  2015-10-28 01:23:21      2   \n",
       "3     wfxmuA7LbKZKVLV58EiWBw     0  2015-11-19 03:48:40      0   \n",
       "4     5jTmjxb1X34EfcY1gos4tw     0  2016-06-04 23:29:46      0   \n",
       "...                      ...   ...                  ...    ...   \n",
       "1995  rKl9yHz4LmQzD70yXBaRlg     0  2016-04-24 02:43:01      0   \n",
       "1996  Hqs4YNST_ZHbshwyi4bnsQ     3  2017-12-30 08:01:06      1   \n",
       "1997  46hnat0aLao-qYWZkN9aBg     1  2010-03-28 15:40:22      1   \n",
       "1998  BGGQOJQTQerEQu0kHbT_UQ     0  2016-05-02 22:24:13      0   \n",
       "1999  I_a74zmgR-X03LsKISWPcg     1  2017-07-08 00:16:47      0   \n",
       "\n",
       "                   review_id  \\\n",
       "0     b8-ELBwhmDKcmcM8icT86g   \n",
       "1     rBpAJhIen_V-zLoXZIcROg   \n",
       "2     _pALaDG6se9OTkGGhyhnNA   \n",
       "3     ru8fpA1Uk0tTFtO5hLM49g   \n",
       "4     fRPgwuFoY6SriToXZyaOQA   \n",
       "...                      ...   \n",
       "1995  oZxqo6rspUimmoqKl0_qdA   \n",
       "1996  C_oCpNq91uTtOYUs2cChdg   \n",
       "1997  qMrxDB5fm8wIzexUp643xQ   \n",
       "1998  HrejfPp6Xduy5Pv7i-is1A   \n",
       "1999  cXo09g5VbXvLHtg52wqhdg   \n",
       "\n",
       "                                                   text  useful  \\\n",
       "0     I took the UP Train to Union Station to catch ...       0   \n",
       "1     We worked with Fitness with a Twist for part o...       1   \n",
       "2     It's your typical, average, run-of-the-mill co...       1   \n",
       "3     We went to Outback today to celebrate my daugh...       0   \n",
       "4     We Went to see Nashville unplugged a country c...       1   \n",
       "...                                                 ...     ...   \n",
       "1995  This was an ok Burger joint. This chain is big...       1   \n",
       "1996  Came here on a whim as we were passing through...       3   \n",
       "1997  This is my favorite Mexican food place on the ...       1   \n",
       "1998  Stopped in here on 3/24/16 around 8pm when the...       0   \n",
       "1999  Who knew that you could get really good Asian ...       0   \n",
       "\n",
       "                     user_id  \n",
       "0     9Lglv-v8SRo_S-IyvFBmbw  \n",
       "1     zIl62G84XT2BwSIAjjjvYw  \n",
       "2     WP7FsUsgNW24s7HH5xi7pg  \n",
       "3     yLSj54f2YgGQu-lhPIhMTQ  \n",
       "4     73-u0a3G9Le4GWG7zLYWtg  \n",
       "...                      ...  \n",
       "1995  XxG5SZOPkihWeJe3r9XL8Q  \n",
       "1996  acPFDB6xB5qtcwTCI2wLvg  \n",
       "1997  TJoILHOxI_K5kJUye0BtbA  \n",
       "1998  PTHCHcBhJbyNS3hMSQ2pYQ  \n",
       "1999  Q8BS0HbtMqH295h46UsL7w  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "x_train = train_df['text']\n",
    "y_train = train_df['stars']\n",
    "x_valid = valid_df['text']\n",
    "y_valid = valid_df['stars']\n",
    "x_test = test_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can use the valid data to choose the hyperparameter.\n",
    "# In this case, you can decide which value of C (1 or 100) is better by evaluating on the valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the first linear model with TFIDF feature\n",
    "tfidf = TfidfVectorizer()\n",
    "lr1 = LogisticRegression(C=100)\n",
    "steps = [('tfidf', tfidf),('lr', lr1)]\n",
    "pipe1 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('lr', LogisticRegression(C=100))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the first model\n",
    "pipe1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.76       517\n",
      "           2       0.37      0.28      0.32       278\n",
      "           3       0.39      0.42      0.41       344\n",
      "           4       0.45      0.49      0.47       427\n",
      "           5       0.66      0.63      0.64       434\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.55      0.55      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[398  66  39   7   7]\n",
      " [ 87  79  76  24  12]\n",
      " [ 32  56 145  94  17]\n",
      " [ 12   9  91 209 106]\n",
      " [  6   6  18 131 273]]\n",
      "accuracy 0.552\n"
     ]
    }
   ],
   "source": [
    "# do the validation of your validation set on the hyper-parameter\n",
    "y_pred = pipe1.predict(x_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the second linear model with TFIDF feature\n",
    "tfidf = TfidfVectorizer()\n",
    "lr2 = LogisticRegression(C=1)\n",
    "steps = [('tfidf', tfidf),('lr', lr2)]\n",
    "pipe2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('lr', LogisticRegression(C=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the second model\n",
    "pipe2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.88      0.78       517\n",
      "           2       0.41      0.19      0.26       278\n",
      "           3       0.48      0.45      0.46       344\n",
      "           4       0.50      0.53      0.52       427\n",
      "           5       0.68      0.70      0.69       434\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.55      0.55      0.54      2000\n",
      "weighted avg       0.58      0.60      0.58      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[453  27  19  13   5]\n",
      " [114  54  79  21  10]\n",
      " [ 45  37 155  93  14]\n",
      " [ 17  11  61 226 112]\n",
      " [ 19   2  11  97 305]]\n",
      "accuracy 0.5965\n"
     ]
    }
   ],
   "source": [
    "# do the validation of your validation set on the hyper-parameter\n",
    "y_pred = pipe2.predict(x_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We find the second model (pipe2) is better, then we use the second model to make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = pipe2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, ..., 5, 5, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your predictions\n",
    "pred_df = pd.DataFrame({'stars': predict_test, 'review_id': test_df['review_id']})\n",
    "pred_df.to_csv('pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then you can submit your predictions `pred.csv` on test set. TAs will evaluate your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
